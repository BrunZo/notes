export const title = "Happiness = d/dt return";
export const date = new Date("2025-12-21 15:00:00");
export const abstract = `Interpretation of hedonic adaptation as a subtle manifestation of the global-local phenomenon in life designing.
This effect is apparently telling that happiness should be the derivative of some mysterious function.`;
export const tags = ["thoughts", "growth"];

I'm going to disprove the claim "we always want to choose the option that maximizes happiness". (Actually, I'll kind of disprove it, as you'll see later.) 

Suppose we're given two people:
- Person A has a 10,000 \$ net worth. However, one day, she receives a bonus paycheck which makes her net worth increase to 20,000 \$.
- Person B has a 1,000,000 \$ net worth. However, that same day, burglars enter her department taking valuable possessions and reducing its net worth to 900,000 \$.

**First question:** Which person would claim to be happier if asked that day?
Generally speaking, people tend to perceive losses as more negative than gains of the same absolute value are perceived as positive. 
In this case, given that the amount lost by B is even bigger than the amount lost by A, it should be even clearer that A will surely claim to be happier.
This is a cousin effect to hedonic adaptation: given two people, one of who should have a slightly higher set point, the happiness would be more faithfully represented not by that set point but by the recent events on each person life.

**Second question:** Which person would *you* prefer to be?
This question is trickier. Naturally, option B is rationally better, as B has a greater net worth. 
Furthermore, if the chosen scenario should be maintained for, say, at least one year, I'd sincerely chose option B, and I'm confident that I'm not alone in this choice.

If you answered like me in the second question, then you understood what I meant with "we don't always want to maximize happiness". 
In fact, it seems like happiness is just the local manifestation (improvement or deterioration) of some global state (one's welfare). 

Another way of saying this could be that happiness is the (discrete?) derivative of the actual measure we want to maximize. 
Returning to person B, it's clear that while achieving the 1M \$ net worth, she must've experienced plenty of happy moments on each of her accepted job applications, promotions, bonus paychecks, etc. 
In other words, what we want to maximize is something more akin to the **integral of happiness** throughout our life (this is why I say I'd "kind of" disprove the initial claim, as, at this point, I've only restated it in a clearer way). Thus, we could think of the return (see [[roti]]) as how does that choice impact the integral of happiness.

## A counterexample
When we're developing a skill, the happiness we feel while practicing it is related to the difference between out current skill and the difficulty of what we're trying to do. Namely:
$$
\text{Happiness} = \text{Skill} - \text{Difficulty}
$$
Thus, we struggle when we try things harder than our current skill and enjoy doing things that feel easy. 

Given some fixed task (with constant difficulty) we want to master, of course we want to maximize happiness, as happiness is linearly related to skill. However, if we want to master a skill (such as playing an instrument), we can only increase our skill by practicing more difficult things, namely, by doing things with negative happiness.